{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMixtureModel(nn.Module):\n",
    "    def __init__(self, n_components, n_features):\n",
    "        super(GaussianMixtureModel, self).__init__()\n",
    "        self.n_components = n_components\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        # Initialize parameters: weights, means, and covariances\n",
    "        self.weights = nn.Parameter(torch.ones(n_components) / n_components, requires_grad=True)  # Mixing coefficients\n",
    "        self.means = nn.Parameter(torch.randn(n_components, n_features), requires_grad=True)  # Means of Gaussians\n",
    "        self.covariances = nn.Parameter(torch.eye(n_features).repeat(n_components, 1, 1), requires_grad=True)  # Covariances\n",
    "    \n",
    "    def gaussian_pdf(self, X, mean, covariance):\n",
    "        \"\"\"Compute the probability density function of a Gaussian.\"\"\"\n",
    "        n_features = X.size(1)\n",
    "        diff = X - mean\n",
    "        \n",
    "        # Compute the determinant and inverse of the covariance matrix\n",
    "        det_cov = torch.det(covariance)\n",
    "        inv_cov = torch.inverse(covariance)\n",
    "        \n",
    "        # Calculate exponent term\n",
    "        exponent = -0.5 * (diff.unsqueeze(-2) @ inv_cov @ diff.unsqueeze(-1)).squeeze()\n",
    "        \n",
    "        # Calculate Gaussian PDF\n",
    "        return (1.0 / ((2 * torch.pi) ** (n_features / 2) * det_cov.sqrt())) * torch.exp(exponent)\n",
    "    \n",
    "    def e_step(self, X):\n",
    "        \"\"\"Expectation step: compute the responsibilities.\"\"\"\n",
    "        likelihoods = torch.stack([self.gaussian_pdf(X, self.means[k], self.covariances[k]) for k in range(self.n_components)])\n",
    "        weighted_likelihoods = self.weights.unsqueeze(1) * likelihoods\n",
    "        responsibilities = weighted_likelihoods / (weighted_likelihoods.sum(dim=0) + 1e-9)\n",
    "        return responsibilities\n",
    "    \n",
    "    def m_step(self, X, responsibilities):\n",
    "        \"\"\"Maximization step: update weights, means, and covariances.\"\"\"\n",
    "        Nk = responsibilities.sum(dim=1)\n",
    "        self.weights.data = Nk / X.size(0)\n",
    "        \n",
    "        # Update means\n",
    "        for k in range(self.n_components):\n",
    "            self.means.data[k] = (responsibilities[k].unsqueeze(-1) * X).sum(dim=0) / Nk[k]\n",
    "            \n",
    "            # Update covariances\n",
    "            diff = X - self.means[k]\n",
    "            self.covariances.data[k] = (responsibilities[k].unsqueeze(-1) * diff.unsqueeze(-1) @ diff.unsqueeze(-2)).sum(dim=0) / Nk[k]\n",
    "    \n",
    "    def fit(self, X, n_iterations=100):\n",
    "        \"\"\"Fit the GMM to the data using the EM algorithm.\"\"\"\n",
    "        for i in range(n_iterations):\n",
    "            responsibilities = self.e_step(X)\n",
    "            self.m_step(X, responsibilities)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict cluster labels for the data.\"\"\"\n",
    "        responsibilities = self.e_step(X)\n",
    "        return responsibilities.argmax(dim=0)\n",
    "\n",
    "# Example usage:\n",
    "n_samples, n_features, n_components = 100, 2, 3\n",
    "X = torch.randn(n_samples, n_features)  # Generate some random data\n",
    "\n",
    "gmm = GaussianMixtureModel(n_components=n_components, n_features=n_features)\n",
    "gmm.fit(X, n_iterations=100)\n",
    "labels = gmm.predict(X)\n",
    "\n",
    "print(\"Cluster labels:\", labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
